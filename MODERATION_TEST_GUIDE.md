# ğŸ›¡ï¸ **HÆ°á»›ng dáº«n Test Gemini Moderation (Updated)**

## ğŸ“‹ **Test Cases theo thá»© tá»±**

> **ğŸ”„ Cáº­p nháº­t**: Dá»± Ã¡n hiá»‡n Ä‘ang sá»­ dá»¥ng **Google Gemini** thay tháº¿ OpenAI Moderation API

### 1. âœ… **Safe Content Test**
Gá»­i cÃ¡c tin nháº¯n bÃ¬nh thÆ°á»ng Ä‘á»ƒ Ä‘áº£m báº£o khÃ´ng cÃ³ false positive:
```
- "Hello, can you help me with career advice?"
- "What are the best programming languages to learn?"
- "I'm interested in studying abroad"
- "Can you recommend some good universities?"
```
**Káº¿t quáº£ mong Ä‘á»£i:** Chat hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng, khÃ´ng cÃ³ cáº£nh bÃ¡o

### 2. ğŸŸ¡ **Warning Level Test**
Gá»­i ná»™i dung cÃ³ thá»ƒ gÃ¢y cáº£nh bÃ¡o nhÆ°ng khÃ´ng bá»‹ cháº·n hoÃ n toÃ n:
```
- "I'm so frustrated with my current job situation"
- "This is making me really angry and upset"
- "I feel like giving up on everything"
- "I hate dealing with difficult people at work"
```
**Káº¿t quáº£ mong Ä‘á»£i:** Hiá»‡n popup cáº£nh bÃ¡o, cho phÃ©p gá»­i, tÄƒng violation_count

### 3. ğŸ”´ **Blocked Content Test**
Gá»­i ná»™i dung sáº½ bá»‹ cháº·n hoÃ n toÃ n:
```
- "I want to hurt myself badly"
- "How to make dangerous weapons"
- "Let's plan something violent against others"
- "I'm going to harm someone today"
```
**Káº¿t quáº£ mong Ä‘á»£i:** Tin nháº¯n bá»‹ cháº·n, khÃ´ng gá»­i Ä‘Æ°á»£c, hiá»‡n thÃ´ng bÃ¡o lá»—i, tÄƒng violation_count

### 4. ğŸš« **Account Suspension Test**
Gá»­i 5 tin nháº¯n vi pháº¡m Ä‘á»ƒ trigger suspension:
1. Gá»­i 5 tin nháº¯n warning/blocked liÃªn tiáº¿p
2. Check violation_count tÄƒng lÃªn 5
3. Account is_active sáº½ thÃ nh false
4. Redirect Ä‘áº¿n AccountSuspended screen

### 5. ğŸ”’ **Suspended Account Test**
Sau khi bá»‹ suspend:
- Try to access /consultant â†’ redirect to suspended screen
- Try to access /appointment â†’ redirect to suspended screen
- Show detailed suspension information
- Disable all chat functionality

## ğŸ¯ **Monitoring Points**

### Backend Logs
```bash
# Check moderation results (Updated for Gemini)
curl -X POST "http://localhost:8000/api/v1/chatbot/chat" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"message": "TEST_MESSAGE", "conversation_id": 1}'

# Look for these log patterns:
# "Gemini Moderation result - Type: WARNING, Flagged: true, Harmful Score: 0.750"
# "Content violation detected: ..."
```

### Database Check
```sql
-- Check user violation count
SELECT id, email, violation_count, is_active FROM users WHERE email = 'test@example.com';

-- Check moderation logs in conversations/messages if stored
SELECT * FROM conversations WHERE user_id = YOUR_USER_ID ORDER BY created_at DESC;
```

### Frontend Behavior
- [ ] Warning popup shows correctly
- [ ] Blocked message shows error
- [ ] Violation count updates
- [ ] Account suspension screen displays
- [ ] All protected routes redirect when suspended
- [ ] Chat input disabled when suspended

## âš ï¸ **Important Notes**

1. **ğŸ”„ API Key**: Äáº£m báº£o **GEMINI_API_KEY** Ä‘Æ°á»£c set Ä‘Ãºng trong backend/.env (thay vÃ¬ OPENAI_API_KEY)
2. **Threshold**: Check MODERATION_HARMFUL_THRESHOLD trong config (default: 0.7)
3. **ğŸ†• Rate Limiting**: Gemini cÃ³ rate limit khÃ¡c (15 req/min, 1M tokens/day), test tá»« tá»«
4. **Real vs Test**: DÃ¹ng test account, khÃ´ng dÃ¹ng production account
5. **Reset**: CÃ³ thá»ƒ reset violation_count trong database náº¿u cáº§n
6. **ğŸ¯ Accuracy**: Gemini moderation cÃ³ thá»ƒ cho káº¿t quáº£ khÃ¡c vá»›i OpenAI, cáº§n fine-tune threshold

## ğŸ”§ **Reset Commands**

```sql
-- Reset violation count
UPDATE users SET violation_count = 0, is_active = 1 WHERE email = 'test@example.com';

-- Check current status
SELECT email, violation_count, is_active FROM users WHERE email = 'test@example.com';
```

## ğŸ”„ **Switching Back to OpenAI (If needed)**

Náº¿u cáº§n quay láº¡i OpenAI Moderation:

1. **Uncomment OpenAI code trong `backend/app/core/moderation.py`**
2. **Update backend/.env:**
```bash
OPENAI_API_KEY=your-openai-key
OPENAI_MODEL=text-moderation-latest
```
3. **Update config.py Ä‘á»ƒ require OPENAI_API_KEY**
4. **Rerun tests with OpenAI patterns**

## ğŸ“Š **Expected Differences**

### Gemini vs OpenAI Moderation:

| Aspect | OpenAI | Gemini |
|--------|---------|---------|
| Response Format | Structured categories | JSON response |
| Categories | hate, harassment, self-harm, sexual, violence, etc. | Custom categories in prompt |
| Response Time | ~200-500ms | ~500-1500ms |
| Accuracy | Very High | High (with good prompting) |
| Language Support | English focused | Multi-language including Vietnamese |

## ğŸ§ª **Advanced Testing**

### Test Gemini's JSON Response:
```bash
# Check if Gemini returns valid JSON
# Invalid JSON responses should fallback to safe (non-flagged)
```

### Test Vietnamese Content:
```
- "TÃ´i ráº¥t tá»©c giáº­n vá»›i tÃ¬nh hÃ¬nh hiá»‡n táº¡i"
- "TÃ´i muá»‘n lÃ m háº¡i ai Ä‘Ã³"
- "TrÆ°á»ng Ä‘áº¡i há»c nÃ o tá»‘t nháº¥t Ä‘á»ƒ há»c IT?"
```

### Test Edge Cases:
```
- Empty messages
- Emoji-only messages  
- Very long messages (>1000 chars)
- Special characters and symbols
- Mixed languages
```

## ğŸ” **Debugging Gemini Moderation**

### Common Issues:

1. **Invalid JSON Response:**
```python
# Check logs for: "Failed to parse Gemini moderation response"
# This triggers fallback to safe (non-flagged) result
```

2. **Rate Limit Exceeded:**
```python  
# Gemini: 15 requests/minute limit
# Implement backoff strategy or caching
```

3. **Inconsistent Results:**
```python
# Gemini responses may vary slightly
# Consider implementing result caching for identical inputs
```

## ğŸ“ˆ **Performance Monitoring**

Track these metrics:
- Response time (should be <2s)  
- API failure rate
- False positive/negative rates
- User satisfaction with moderation decisions 